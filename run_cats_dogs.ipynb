{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "# 0: infos, warning, errors.\n",
    "# 1: warnings, errors.\n",
    "# 2: errors.\n",
    "# 3: none.\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", physical_devices)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from ocml.datasets import tfds_from_sampler, tf_from_tfds, zip_ds\n",
    "from ocml.evaluate import check_LLC, log_metrics\n",
    "from ocml.models import spectral_VGG, spectral_VGG_V2\n",
    "from ocml.plot import plot_preds_ood, plot_imgs_grid, plot_gan\n",
    "from ocml.priors import uniform_image, Mnist_NDA\n",
    "from ocml.train import train, SH_KR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import math\n",
    "\n",
    "\n",
    "def perc_to_margin(img_size, num_channels, perc, domain):\n",
    "    return perc * (img_size * img_size * num_channels * (domain[1] - domain[0]))**0.5\n",
    "\n",
    "def get_config(debug=False):\n",
    "  domain = [-2., 2.]  # required for images.\n",
    "  # heuristic of https://arxiv.org/abs/2206.06854\n",
    "  ratio_images = 0.5 / 100\n",
    "  ratio_pixels = 0.5 / 100\n",
    "  margin = perc_to_margin(28, 1, ratio_pixels, domain)  # 5% pixels for real images\n",
    "  lbda = 1. / ratio_images  \n",
    "  print(f\"Margin={margin:.3f} Lambda={lbda:.3f}\")\n",
    "  dataset_name = \"cats_vs_dogs\"\n",
    "  config = SimpleNamespace(\n",
    "    dataset_name = dataset_name,\n",
    "    # Newton-Raphson.\n",
    "    maxiter = 50,\n",
    "    eta = 20.,\n",
    "    level_set = - margin * 1.5,\n",
    "    batch_size = 128,\n",
    "    domain = domain,\n",
    "    margin = margin,\n",
    "    lbda = lbda,\n",
    "    domain_clip = True,\n",
    "    deterministic = False,\n",
    "    negative_augmentation = True,\n",
    "    overshoot_boundary = False,\n",
    "    # architecture.\n",
    "    k_coef_lip = 1.,\n",
    "    strides = False,\n",
    "    spectral_dense = True,\n",
    "    pooling = True,\n",
    "    global_pooling = False,\n",
    "    groupsort = True,\n",
    "    conv_widths = [256, 256, 256],\n",
    "    dense_widths = [256, 256, 256],\n",
    "    # training.\n",
    "    in_labels = [0],\n",
    "    warmup_epochs = 10,\n",
    "    epochs_per_plot = 40,\n",
    "  )\n",
    "  return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = \"SANDBOX\" in os.environ\n",
    "config = get_config(debug)\n",
    "train_kwargs = {\n",
    "  'domain': config.domain,\n",
    "  'eta': config.eta,\n",
    "  'deterministic': config.deterministic,\n",
    "  'level_set': config.level_set,\n",
    "  'overshoot_boundary': config.overshoot_boundary\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "print(\"PLOTLY_RENDERER:\", pio.renderers.default)\n",
    "try:\n",
    "  import wandb\n",
    "  wandb.login()\n",
    "  wandb_available = True\n",
    "except ModuleNotFoundError as e:\n",
    "  print(e)\n",
    "  print(\"Wandb logs will be removed.\")\n",
    "  wandb_available = False\n",
    "plot_wandb = wandb_available and not debug  # Set to False to de-activate Wandb.\n",
    "if plot_wandb:\n",
    "  import wandb\n",
    "  group = os.environ.get(\"WANDB_GROUP\", \"sandbox_fashion_mnist\")\n",
    "  wandb.init(project=\"ocml_fashion\", config=config.__dict__, group=group, save_code=True)\n",
    "else:\n",
    "  try:\n",
    "    wandb.finish()\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "train_kwargs['log_metrics_fn'] = partial(log_metrics, plot_wandb=plot_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 3)\n",
    "model = spectral_VGG_V2(input_shape, k_coef_lip=config.k_coef_lip, scale=1)\n",
    "\n",
    "loss_fn = SH_KR(config.margin, config.lbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from typing import Iterable, Iterator, Mapping, Optional, Sequence, Tuple\n",
    "\n",
    "IMAGE_SIZE = 64 # 112  # 224\n",
    "NUM_OF_CHANNELS = 3\n",
    "CROP_PADDING = 32\n",
    "MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "NUM_IMAGES = 9469\n",
    "\n",
    "def _center_crop(\n",
    "    image: tf.Tensor,\n",
    "    original_shape: Optional[tf.Tensor] = None,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Crops to center of image with padding then scales.\"\"\"\n",
    "    if original_shape is None:\n",
    "        original_shape = tf.shape(image)\n",
    "    image_height = original_shape[0]\n",
    "    image_width = original_shape[1]\n",
    "\n",
    "    padded_center_crop_size = tf.cast(\n",
    "      ((IMAGE_SIZE / (IMAGE_SIZE + CROP_PADDING)) *\n",
    "       tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32)\n",
    "\n",
    "    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n",
    "    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n",
    "    crop_window = tf.stack([offset_height, offset_width,\n",
    "                          padded_center_crop_size, padded_center_crop_size])\n",
    "    image = tf.image.crop_to_bounding_box(image, offset_height, offset_width, padded_center_crop_size, padded_center_crop_size)\n",
    "    return image\n",
    "\n",
    "def _distorted_bounding_box_crop(\n",
    "    image: tf.Tensor,\n",
    "    *,\n",
    "    jpeg_shape: tf.Tensor,\n",
    "    bbox: tf.Tensor,\n",
    "    min_object_covered: float,\n",
    "    aspect_ratio_range: Tuple[float, float],\n",
    "    area_range: Tuple[float, float],\n",
    "    max_attempts: int,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\"\"\"\n",
    "    bbox_begin, bbox_size, _ = tf.image.sample_distorted_bounding_box(\n",
    "      jpeg_shape,\n",
    "      bounding_boxes=bbox,\n",
    "      min_object_covered=min_object_covered,\n",
    "      aspect_ratio_range=aspect_ratio_range,\n",
    "      area_range=area_range,\n",
    "      max_attempts=max_attempts,\n",
    "      use_image_if_no_bounding_boxes=True)\n",
    "\n",
    "    # Crop the image to the specified bounding box.\n",
    "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
    "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
    "    image = tf.image.crop_to_bounding_box(image, offset_y, offset_x, target_height, target_width)\n",
    "    return image\n",
    "\n",
    "def random_crop(image, image_size):\n",
    "    \"\"\"Make a random crop of image_size.\"\"\"\n",
    "    original_shape = tf.shape(image)\n",
    "    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
    "    image = _distorted_bounding_box_crop(\n",
    "      image,\n",
    "      jpeg_shape=original_shape,\n",
    "      bbox=bbox,\n",
    "      min_object_covered=0.1,\n",
    "      aspect_ratio_range=(3 / 4, 4 / 3),\n",
    "      area_range=(0.08, 1.0),\n",
    "      max_attempts=10)\n",
    "    if tf.reduce_all(tf.equal(original_shape, tf.shape(image))):\n",
    "        # If the random crop failed fall back to center crop.\n",
    "        image = _center_crop(image, original_shape)\n",
    "    return image\n",
    "\n",
    "def _normalize_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Normalize the image to zero mean and unit variance.\"\"\"\n",
    "    image -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    image /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    return image\n",
    "\n",
    "def preprocess_cats_dogs(image, filename, label, augmentation):\n",
    "    if augmentation:\n",
    "        image = random_crop(image, IMAGE_SIZE)\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "    else:\n",
    "        image = _center_crop(image)\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE], tf.image.ResizeMethod.BICUBIC)\n",
    "    image = _normalize_image(image)\n",
    "    return image\n",
    "\n",
    "def filter_labels(white_list):\n",
    "  \"\"\"Select images belonging to a white list of labels.\"\"\"\n",
    "  white_list = tf.constant(white_list, dtype=tf.int64)\n",
    "  def filter_fun(image, label):\n",
    "    return tf.math.reduce_any(tf.equal(label, white_list))\n",
    "  return filter_fun\n",
    "\n",
    "def build_cats_dogs(ds_name, batch_size, in_labels, domain, split='train', preprocess_fun=None):\n",
    "  \"\"\"Convert dataset from Tf repository into iterable tf.Dataset.\"\"\"\n",
    "  ds = tfds.load('cats_vs_dogs', split='train', as_supervised=True, shuffle_files=True)\n",
    "  if split in ['train', 'test'] :\n",
    "    label_set = in_labels\n",
    "  elif split == 'ood':\n",
    "    label_set = list(set(range(0, 2)).difference(in_labels))\n",
    "  ds = ds.filter(filter_labels(label_set))\n",
    "  if preprocess_fun is None:\n",
    "    preprocess_fun = preprocess_cats_dogs\n",
    "  augmentation = split == 'train'\n",
    "  ds = ds.map(partial(preprocess_fun, domain=None, augmentation=augmentation))\n",
    "  to_shuffle = 2\n",
    "  if split == 'train':\n",
    "    ds = ds.repeat().shuffle(to_shuffle*batch_size)  # always repeat a dataset\n",
    "  ds = ds.batch(batch_size).prefetch(4)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce and process dataset.\n",
    "p_dataset = build_cats_dogs(config.dataset_name, config.batch_size, in_labels=config.in_labels, domain=config.domain)\n",
    "num_images = 23262\n",
    "epoch_length = math.ceil(num_images*len(config.in_labels)*(1/2) / config.batch_size) if not debug else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer class.\n",
    "decay_steps = epoch_length*(config.warmup_epochs + config.epochs_per_plot*2)\n",
    "initial_learning_rate = 2.5e-4\n",
    "learning_rate =  tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=initial_learning_rate, decay_steps=decay_steps,\n",
    "  end_learning_rate=initial_learning_rate/1000, power=1.)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "# Initialize the network.\n",
    "gen = tf.random.Generator.from_seed(random.randint(0, 1000))\n",
    "p_batch = next(iter(p_dataset))\n",
    "_ = model(p_batch, training=True)  # garbage forward.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial distribution.\n",
    "if config.negative_augmentation:\n",
    "  bs_1, bs_2 = config.batch_size // 2, config.batch_size - (config.batch_size // 2)\n",
    "  q_random = tfds_from_sampler(uniform_image, gen, bs_1, p_batch.shape[1:], domain=config.domain)\n",
    "  q_nda = Mnist_NDA(bs_1, p_batch.shape[1:]).transform(gen, build_ds(config.dataset_name, bs_2, in_labels=config.in_labels))\n",
    "  q_dataset = zip_ds(q_random, q_nda)\n",
    "else:\n",
    "  q_dataset = tfds_from_sampler(uniform_image, gen, config.batch_size, p_batch.shape[1:], domain=config.domain)\n",
    "Q0 = next(iter(q_dataset))\n",
    "plot_imgs_grid(Q0, 'X_ood.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_P = tf.reshape(tf_from_tfds(p_dataset.take(epoch_length)), shape=(-1, 32, 32, 3))\n",
    "X_test = tf_from_tfds(build_cats_dogs(config.dataset_name, config.batch_size, in_labels=config.in_labels, domain=config.domain, split='test'))\n",
    "X_ood = tf_from_tfds(build_cats_dogs(config.dataset_name, config.batch_size, in_labels=config.in_labels, domain=config.domain, split='ood'))\n",
    "print(f'TrainSize={len(X_P)} TestSize={len(X_test)} OODSize={len(X_ood)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_imgs_grid(X_P, 'X_P.png')\n",
    "# plot_imgs_grid(X_test, 'X_test.png')\n",
    "# plot_imgs_grid(X_ood, 'X_ood.png')\n",
    "plot_imgs_grid(Q0, 'X_ood.png')\n",
    "# check_LLC(model, Q0, plot_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "for epoch in range(0, config.warmup_epochs):\n",
    "  print(f\"Epoch={epoch} LR={float(opt._decayed_lr(tf.float32)):.7f}\")\n",
    "  train(model, opt, loss_fn, gen, p_dataset, q_dataset, epoch_length, maxiter=0, **train_kwargs)\n",
    "plot_preds_ood(epoch, model, X_P, X_test, X_ood, plot_histogram=True, plot_wandb=plot_wandb)\n",
    "plot_gan(epoch, model, p_batch, Q0[:16], gen, maxiter=config.maxiter, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_epoch = config.epochs_per_plot+epoch+1\n",
    "for epoch in range(epoch+1, end_epoch):\n",
    "  print(f\"Epoch={epoch} LR={float(opt._decayed_lr(tf.float32)):.7f}\")\n",
    "  train(model, opt, loss_fn, gen, p_dataset, q_dataset, epoch_length, maxiter=config.maxiter, **train_kwargs)\n",
    "  plot_histogram = (epoch+1 == end_epoch)\n",
    "  plot_preds_ood(epoch, model, X_P, X_test, X_ood, plot_histogram=plot_histogram, plot_wandb=plot_wandb)\n",
    "plot_gan(epoch, model, p_batch, Q0[:16], gen, maxiter=config.maxiter, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_epoch = config.epochs_per_plot+epoch+1\n",
    "for epoch in range(epoch+1, end_epoch):\n",
    "  print(f\"Epoch={epoch} LR={float(opt._decayed_lr(tf.float32)):.7f}\")\n",
    "  train(model, opt, loss_fn, gen, p_dataset, q_dataset, epoch_length, maxiter=config.maxiter, **train_kwargs)\n",
    "  plot_histogram = (epoch+1 == end_epoch)\n",
    "  plot_preds_ood(epoch, model, X_P, X_test, X_ood, plot_histogram=plot_histogram, plot_wandb=plot_wandb)\n",
    "plot_gan(epoch, model, p_batch, Q0[:16], gen, maxiter=config.maxiter, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_certificates(model, config, X_train, X_test, X_ood):\n",
    "  # run XPs.\n",
    "  y_train    = model.predict(X_train, batch_size=256, verbose=0).flatten()\n",
    "  y_test     = model.predict(X_test, batch_size=256, verbose=0).flatten()\n",
    "  y_ood      = model.predict(X_ood, batch_size=256, verbose=0).flatten()\n",
    "  \n",
    "  msg = dict()\n",
    "  attacks_radii = [0, 8, 16, 36, 72, 144, 256]\n",
    "  for r in attacks_radii:\n",
    "    e = (r / 255) * (config.domain[1] - config.domain[0])\n",
    "    T_train, acc_train, roc_auc_train = calibrate_accuracy(y_train-e, y_ood+e)\n",
    "    T_test, acc_test, roc_auc_test = calibrate_accuracy(y_test-e, y_ood+e)\n",
    "    msg[f'certificate_r={r:}_train'] = roc_auc_train\n",
    "    msg[f'certificate_r={r:}_test'] = roc_auc_test\n",
    "  print(msg)\n",
    "  wandb.log(msg)\n",
    "  return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_certificates(model, config, X_P, X_test, X_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "\n",
    "def proj_l2_ball(x, x_0, eps):\n",
    "  n = x - x_0\n",
    "  l = tf.reduce_sum(n**2, axis=-1, keepdims=True)**0.5\n",
    "  l = tf.maximum(l, 1e-6 * eps)\n",
    "  factor = tf.where(l > eps, eps / l, 1.)\n",
    "  n = n * factor\n",
    "  x = x_0 + n\n",
    "  return x\n",
    "\n",
    "def random_ball(x_0, eps):\n",
    "  n = tf.random.normal((x_0.shape[0], x_0.shape[1]+1,))\n",
    "  l = tf.reduce_sum(n**2, axis=-1, keepdims=True)**0.5\n",
    "  n = n / (l + eps*1e-6)\n",
    "  n = n[:,:-1]  # drop last coordinate.\n",
    "  x = x_0 + n\n",
    "  return x\n",
    "\n",
    "def gd_step(x, x0, label, eps, model, step):\n",
    "  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    tape.watch(x)\n",
    "    y = model(tf.reshape(x, (-1, 64, 64, 3)), training=False)\n",
    "  g = tape.batch_jacobian(y, x)\n",
    "  g = g[:,0,:]\n",
    "  x = x - step * label * g  # descent: decreases OOD score of OOD, increases of normal data\n",
    "  x = proj_l2_ball(x, x0, eps)\n",
    "  x = tf.clip_by_value(x, -1, 1.)\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def l2_pgd(model, x0, label, eps, attempts=1, random_start=True):\n",
    "  y_best = None\n",
    "  for attempt in range(attempts):\n",
    "    if random_start:\n",
    "      x = random_ball(x0, eps)\n",
    "    else:\n",
    "      x = x0\n",
    "    x = tf.clip_by_value(x, -1, 1.)\n",
    "    max_iter = 50\n",
    "    step = 0.025 * eps\n",
    "    for iter in range(max_iter):\n",
    "      x = gd_step(x, x0, label, eps, model, step)\n",
    "    delta = tf.reduce_mean(tf.reduce_sum((x - x0)**2, axis=-1)**0.5)\n",
    "    y = model(tf.reshape(x, (-1, 64, 64, 3)), training=False)\n",
    "    if y_best is None:\n",
    "      y_best = y\n",
    "    else:\n",
    "      y_min = tf.minimum(y, y_best)\n",
    "      y_max = tf.maximum(y, y_best)\n",
    "      y_best = tf.where(label[:,0] > 0., y_min, y_max)\n",
    "  return y_best, delta\n",
    "\n",
    "def l2_pgd_batch(model, images, labels, eps, batch_size):\n",
    "  scores = []\n",
    "  images = tf.reshape(images, (-1, batch_size, 12288))\n",
    "  labels = tf.reshape(labels, (-1, batch_size, 1))\n",
    "  deltas = [0.]\n",
    "  for x0, label in tqdm.tqdm(zip(images, labels)):\n",
    "    if eps == 0.:\n",
    "      x = tf.reshape(x0, shape=(-1, 64, 64, 3))\n",
    "      score = model(x, training=False)\n",
    "    else:\n",
    "      score, delta = l2_pgd(model, x0, label, eps)\n",
    "      deltas.append(delta)\n",
    "    scores.append(score.numpy().flatten())\n",
    "  scores = np.concatenate(np.array(scores), axis=0)\n",
    "  return scores, deltas\n",
    "\n",
    "def attack(model, config, X_train, X_test, X_ood, batch_size):\n",
    "  X_ood = np.random.permutation(X_ood)[:(len(X_ood) // batch_size)*batch_size]\n",
    "  X_test = np.random.permutation(X_test)[:(len(X_test) // batch_size)*batch_size]\n",
    "  images = tf.constant(np.concatenate([X_test, X_ood], axis=0))\n",
    "  labels = tf.concat([tf.ones((len(X_test),)), -tf.ones((len(X_ood),))], axis=0)\n",
    "  msg = dict()\n",
    "  attacks_radii = [0, 8, 16, 36, 72, 144, 255]\n",
    "  for r in attacks_radii:\n",
    "    e = (r / 255) * (config.domain[1] - config.domain[0])\n",
    "    scores, deltas = l2_pgd_batch(model, images, labels, eps=e, batch_size=batch_size)\n",
    "    deltas = np.mean(np.array(deltas))\n",
    "    print(\"deltas:\", deltas)\n",
    "    msg['deltas'] = deltas\n",
    "    roc_auc_test = roc_auc_score((labels+1)/2, scores)*100\n",
    "    print(f'r={r:}_test={roc_auc_test}%')\n",
    "    msg[f'r={r:}_test'] = roc_auc_test\n",
    "    print(scores[:10], scores[-10:])\n",
    "  print(msg)\n",
    "  wandb.log(msg)\n",
    "  return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack(model, config, X_P, X_test, X_ood, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_wandb:\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "92c440f6d82e79b41f51da7601df579ae39fc115954f77d4b816ac1ce1ea7f75"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "091c2994d1544a68ab89a94f725c5ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "24504d5cee27493f879777200b809d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "424b1f1a15ad4869af4be9eb79247798": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5aee67def05c46d89fe3e97b4f81e3c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aa900e7e22674ff2a249eac4bc804a71",
        "IPY_MODEL_81182c1fb849421784f4e8ebb525e3ee"
       ],
       "layout": "IPY_MODEL_af9ddc5fb82f47a7aaa6b0802393026b"
      }
     },
     "70fc441e72a846d69e7e41a24d163063": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81182c1fb849421784f4e8ebb525e3ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_424b1f1a15ad4869af4be9eb79247798",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_24504d5cee27493f879777200b809d3c",
       "value": 0
      }
     },
     "aa900e7e22674ff2a249eac4bc804a71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_70fc441e72a846d69e7e41a24d163063",
       "placeholder": "​",
       "style": "IPY_MODEL_091c2994d1544a68ab89a94f725c5ed7",
       "value": ""
      }
     },
     "af9ddc5fb82f47a7aaa6b0802393026b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
